[
  {
    "objectID": "week1/week1.html#il-famoso-smoking-ra-fisher",
    "href": "week1/week1.html#il-famoso-smoking-ra-fisher",
    "title": "2  Week 1",
    "section": "2.1 il famoso Smoking RA Fisher",
    "text": "2.1 il famoso Smoking RA Fisher\nWe’ll talk about a lot of the methods that Ronald A. Fisher developed. Already in the 1900s it was being observed that there was a strong association between smoking and lung cancer. However, Fisher was a smoker himself and posited that the association between lung cancer and smoking could be explained away by some genetic or biological difference between the smoking and non-smoking population (positing some genes that caused people to desire to smoke).\n\n\n\n\n\nRonald Fisher’s unsupported theory of genetics confounding the smoking-lung cancer relationship\n\n\n\n\nWe’re pretty sure that this was driven not by any substance matter expertise, but rather by Fisher’s love of smoking."
  },
  {
    "objectID": "week1/week1.html#hormone-replacement-therapy",
    "href": "week1/week1.html#hormone-replacement-therapy",
    "title": "2  Week 1",
    "section": "2.2 Hormone Replacement Therapy",
    "text": "2.2 Hormone Replacement Therapy\nIn the mid- to late- 20th century there were a ton of studies linking hormone replacement therapy for older women to better cardiovascular outcomes (lack of coronary heart disease).\nHowever, thankfully due to the Heart and Estrogen/Progestin Study (HERS, in the early 90s) we now know that a lot of those studies were not controlling for socioeconomic status. It turns out that socioeconomic status was highly associated with HRT usage, and associated at least in the US with a lot of better health outcomes across the board.\nIt turned out that HRT when applied at certain times for some people can actually be harmful — but the point is the picture is much muddier than was initially thought and recommendations were rolled back. Later randomized studies were performed that produced reliable bodies of evidence demonstrating either no effect or in some cases harmful effects.\nWe’ll use the baseline data from HERS (not so much interested in the HRT treatment effect), but to investigate the research question:\n\nHow is systolic blood pressure related to age, independently of other well-known cardiovascular risk factors? (Age, diabetes, smoking, etc.)"
  },
  {
    "objectID": "week1/week1.html#prediction-studies",
    "href": "week1/week1.html#prediction-studies",
    "title": "2  Week 1",
    "section": "2.3 Prediction Studies",
    "text": "2.3 Prediction Studies\nTypically in prediction settings, there’s no single exposure of particular interest; mechanisms and confounding is treated as less of a concern (if at all), and the main challenge is that we need to take care to not overfit the data.\nA major theme of this class will be that different tasks require different analysis strategies and diffrent statistical tools."
  },
  {
    "objectID": "week1/week1.html#quantifying-uncertainty",
    "href": "week1/week1.html#quantifying-uncertainty",
    "title": "2  Week 1",
    "section": "2.4 Quantifying Uncertainty",
    "text": "2.4 Quantifying Uncertainty\nTypically standard statistical models have nice theoretical properties because years-and-years ago, we didn’t have much data so people spent their time studying theory instead of data. As a result, we have a lot of nice theories about the uncertainty represented in statistical models.\nAn example of the kind of uncertainty we might be interested in is shown in this figure relating Alzheimer’s disease rates and exposure to PM2.5.\n\n\n\n\n\n\n\n\n\nThis figure is taken from the article Long-term effects of PM2·5 on neurological disorders in the American Medicare population: a longitudinal cohort study by Shi et al, Lancet Planetary Health (2020)."
  },
  {
    "objectID": "week1/week1.html#why-learn-methods-before-study-design",
    "href": "week1/week1.html#why-learn-methods-before-study-design",
    "title": "2  Week 1",
    "section": "2.5 Why Learn Methods Before Study Design",
    "text": "2.5 Why Learn Methods Before Study Design\nAn interesting point made is that it’s important to understand the limitations, strengths of methods, what they can and can’t do, and how to use them before designing a study."
  },
  {
    "objectID": "week1/week1.html#recommended-reading",
    "href": "week1/week1.html#recommended-reading",
    "title": "2  Week 1",
    "section": "2.6 Recommended Reading",
    "text": "2.6 Recommended Reading\nKutner M, Nachtsheim C, Neter J, Li W. Applied Linear Statistical Model. 5th edition. chapters 1-3\nShmueli, G. (2010). To explain or to predict? Statistical Science. https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf"
  },
  {
    "objectID": "week1/week1.html",
    "href": "week1/week1.html",
    "title": "Week 1",
    "section": "",
    "text": "Introductory Overview\nJeffrey Miller’s office hours: Noon-1pm on Thursdays\nTA: Cathy Xue Office hours: 5:30-6:30pm on Tuesdays in 2-434 (Building 2, Room 434)"
  },
  {
    "objectID": "week1/week1.html#course-description",
    "href": "week1/week1.html#course-description",
    "title": "Week 1",
    "section": "Course description:",
    "text": "Course description:\n\nAxiomatic foundations of probability, independence, conditional probability, joint distributions, transformations, moment generating functions, characteristic functions, moment inequalities, sampling distributions, modes of convergence and their interrelationships, laws of large numbers, central limit theorem, and stochastic processes"
  },
  {
    "objectID": "week1/week1.html#course-readings",
    "href": "week1/week1.html#course-readings",
    "title": "Week 1",
    "section": "Course Readings:",
    "text": "Course Readings:\n\nStatistical Inference (Second Edition), by George Casella and Roger L. Berger. Cengage Learning, 2021.\nProbability: Theory and Examples (Fourth Edition), by Richard Durrett. Cambridge University Press, 2010. (https://services.math.duke.edu/~rtd/PTE/PTE5_011119.pdf)\nIntroduction to Stochastic Processes (Second Edition), by Gregory F. Lawler. Chapman & Hall/CRC, 2006.\n\nThe Durrett book is more measure-theoretic, but covers some things better (according to Miller) than Casella and Berger. Lawler’s book is a gentle introduction to stochastic processes."
  },
  {
    "objectID": "week1/week1.html#labs",
    "href": "week1/week1.html#labs",
    "title": "Week 1",
    "section": "Labs",
    "text": "Labs\nWeekly Tuesdays at 3:45-5:15 in FXB G10"
  },
  {
    "objectID": "week1/week1.html#outline-of-topics",
    "href": "week1/week1.html#outline-of-topics",
    "title": "Week 1",
    "section": "Outline of Topics",
    "text": "Outline of Topics\n\nFundamentals (CB 1.1 - 1.2.2)\n\nSet theory basics, Measure theory basics, Properties of probability measures\n\nProbability basics (CB 1.2.3 - 1.6)\n\nCombinatorics, Conditional probability and Independence, Random variables\n\nTransformations of random variables (CB 2.1)\n\nChange of variable formula for r.v.s, Probability integral transform\n\nExpectations of random variables CB 2.2 - 2.4)\n\nMean and variance, Moments, MGFs, Differentiation and limits of integrals\n\nFamilies of distributions (CB 3.1 - 3.5)\n\nDiscrete and continuous families, exponential families, location-scale families\n\nInequalities (CB 3.6, 3.8, 4.7)\n\nMarkov, Chebyshev, Gauss, Hölder, Cauchy-Schwarz, Minkowski, Jensen\n\nMultiple random variables (CB 4.1 - 4.6)\n\nRandom vectors, conditional distributions, independence, mixtures, covariance and correlation\n\nGaussian distributions (Bishop pp. 78-93, in Files/Reading on Canvas site)\n\nMultivariate normal, marginals and conditionals, linear-Gaussian model\n\nStatistics of a random sample (CB 5.1 - 5.4)\n\nSampling distributions, Sums of random variables, Student’s t and Snedecor’s F distribution, Order statistics and friends\n\nAsymptotics (CB 5.5)\n\nModes of convergence, Limit theorems, Delta method, Borel-Cantelli lemma\n\nLaws of large numbers (CB 5.5, D 2.2 - 2.4)\n\nWeak laws of large numbers, Strong laws of large numbers, Generalizations\n\nCentral limit theorems (CB 5.5, D 3.1 - 3.4)\n\nWeak convergence, characteristic functions, central limit theorems\n\nGenerating random samples (CB 5.6)\n\nInverse cdf method, accept/reject method, Markov chain Monte Carlo\n\nStochastics processes (L 1 - 3)\n\nMarkov chains, Random walks, Branching processes, Poisson processes"
  },
  {
    "objectID": "week1/week1.html#introduction",
    "href": "week1/week1.html#introduction",
    "title": "Week 1",
    "section": "Introduction",
    "text": "Introduction\nHow could we tell if either of the two sequences were faked.\n\nstr1 <- \"1 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1\"\n\nstr2 <- \"1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0\"\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nstr_count(str1, \"0|1\")\n\n[1] 100\n\nstr_count(str1, \"1\")\n\n[1] 43\n\nstr_count(str1, \"0\")\n\n[1] 57\n\nstr_count(str2, \"0|1\")\n\n[1] 100\n\nstr_count(str2, \"1\")\n\n[1] 53\n\nstr_count(str2, \"0\")\n\n[1] 47\n\nstr1_num <- as.numeric(unlist(stringr::str_split(str1, \" \")))\nstr2_num <- as.numeric(unlist(stringr::str_split(str2, \" \")))\n\n# the first way I proposed was to look at the probability of \n# the coin being \"fair\" given the beta distribution parameterized \n# by the observed coinflips \nx <- seq(0,1,0.01)\ncurve(dbeta(x, str_count(str1, \"0\")+1, str_count(str1, \"1\")+1))\n\n\n\ncurve(dbeta(x, str_count(str2, \"0\")+1, str_count(str2, \"1\")+1))\n\n\n\n# then we tried looking at the running mean\nplot(1:100, cummean(str1_num), type='l')\n\n\n\nplot(1:100, cummean(str2_num), type='l')\n\n\n\n# another classmate suggested that the human-generated \n# sequence may have more anti-correlation than the\n# real sequence because more anti-correlation \"looks\" more\n# random \ncor(lag(str1_num), str1_num, use = 'pairwise.complete.obs')\n\n[1] 0.007518797\n\ncor(lag(str2_num), str2_num, use = 'pairwise.complete.obs')\n\n[1] -0.2367884\n\n\nMiller suggests we could also look at it as a sequence of random variables.\n\nstr1_as_geometric_series <- sapply(unlist(stringr::str_split(stringr::str_remove_all(str1, \" \"), \"1\")), nchar)\nunname(str1_as_geometric_series)\n\n [1] 0 4 2 0 2 0 3 0 0 0 0 3 0 0 0 3 3 8 0 0 3 0 1 3 0 1 0 5 0 1 2 1 0 3 1 0 1 2\n[39] 1 1 0 2 1 0\n\nstr2_as_geometric_series <- sapply(unlist(stringr::str_split(stringr::str_remove_all(str2, \" \"), \"1\")), nchar)\nunname(str2_as_geometric_series)\n\n [1] 0 0 2 3 0 0 1 1 3 1 0 0 1 3 0 0 0 3 0 1 1 0 0 3 1 0 1 1 2 0 0 0 1 1 1 2 0 1\n[39] 2 1 2 0 0 1 0 0 2 0 0 1 1 1 1 1\n\ncurve(dgeom(x, prob = .5), from = 0, to = 10, n = 11)"
  },
  {
    "objectID": "week1/week1.html#history-of-probability",
    "href": "week1/week1.html#history-of-probability",
    "title": "Week 1",
    "section": "History of Probability",
    "text": "History of Probability\nGames of chance have been played for millenia. Early dice games were played with “astragali”, or “knucklebones”, from the ankle of a sheep or goat.\n\n\n\n\n\n\n\n\n\nEgyptian tomb paintings from 3500 BC show games played with astragali, and ancient Greek vases show young men tossing the bones into a circle. Gambling in these games was common, so it would have been advantageous to have some understanding of probability.\nInterest in gambling led mathematicians in the 1500-1600s to begin to formalize the rules of probability.\nTwo players put equal money in a pot. The first player to win 8 rounds of a game gets all the money. If they have to stop before finishing, how should the money be divided between them based on how much they would have won, on average?\nAround 1654, Blaise Pascal and Pierre de Fermat developed the concept of expected value to solve this problem.\nChristiaan Huuygens built upon this in his 1657 textbook on probability, “De Ratiociniis in Ludo Aleae” (“The Value of all Chances in Games of Fortune,”)\nIn the early 1700s, Jacob Bernoulli and Abraham De Moivre wrote foundational books on probability.\nThey systematically developed the mathematics of probability, focusing primarily on discrete problems.\nCombinatorial approaches were developed to handle difficult probability calculations.\nBernoulli proved the first version of the law of large numbers.\nIn 1812, Pierre-Simon Laplace published his book “Théorie analytique des probabilités”.\nLaplace developed or advanced many key methods and results in modern probability and statistics.\nGenerating functions, characteristic functions, linear regression, density functions, Bayesian inference, and hypothesis testing.\nHe employed advanced calculus and real/complex analysis,\ntaking probability calculations to a whole new level.\nLaplace proved the first general version of the central limit theorem.\nIn the 1930s, Andrey Kolmogorov introduced the measure theoretic foundations of modern probability.\nMeasure theory had recently been developed to resolve certain paradoxes that arose in defining volume and integration.\nKolmogorov applied measure theory to put probability on solid theoretical footing.\nThis is particularly important for limits and derivatives of integrals, conditional distributions, and stochastic processes."
  },
  {
    "objectID": "week1/week1.html#set-theory-basics",
    "href": "week1/week1.html#set-theory-basics",
    "title": "Week 1",
    "section": "Set Theory Basics",
    "text": "Set Theory Basics\nThe sample space denoted \\(S\\) is the set of possible outcomes of an experiment.\nExamples include \\(S = \\{ H, T \\}\\) for a coin toss, or math SAT scores \\(S = \\{ 200, 201, ..., 799, 800 \\}\\), or time-to-events: \\(S = (0, \\infty)\\).\nWe say that an event \\(E\\) is a subset of \\(S\\) that is \\(E \\subset S\\).\nA set \\(A\\) is a collection of elements. We say that \\[A \\cup B = \\{ x \\colon x \\in A \\text{ or } x \\in B \\}.\\]\n\\[A \\cap B = \\{ x \\colon x \\in A \\text{ and } x \\in B \\}.\\]\n\\[A^c = \\{ x \\in S \\colon x \\not \\in A \\}\\]\n\\[A \\backslash B = \\{ x \\colon x \\in A \\text{ and } x \\not \\in B \\}.\\]\nThe empty set is denoted \\(\\varnothing = \\{\\}\\).\n\\(A \\subset B\\) means that if \\(x \\in A\\) then \\(x \\in B\\).\n\nProperties of Set Operations\nCommutativity:\n\\[A \\cup B = B \\cup A, \\quad A \\cap B = B \\cap A\\]\nAssociativity:\n\\[\nA \\cup (B \\cup C) = (A \\cup B) \\cup C \\quad\nA \\cap (B \\cap C) = (A \\cap B) \\cap C\n\\]\nDistributive Laws:\n\\[ A \\cup (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\n\\quad\nA \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\]\nDeMorgan’s Laws:\n\\[ (A \\cup B)^c = A^c \\cap B^c \\quad\n(A \\cap B)^c = A^c \\cup B^c \\]\n\n\nSigma Algebras\nDefinition. Suppose that \\(\\mathcal B\\) is a set of subsets of a sample space \\(S\\). Then \\(\\mathcal B\\) is a sigma-algebra if:\n\n\\(\\varnothing \\in \\mathcal B\\).\nif \\(A \\in \\mathcal B\\) then \\(A^c \\in \\mathcal B\\).\nif \\(A_1, A_2, ... \\in \\mathcal B\\) then \\(\\bigcup_{i=1}^\\infty A_i \\in \\mathcal B\\)\n\n\nThe powerset, denoted \\(2^S\\) is a specific example of a sigma algebra.\n\n\n\nWe have to be very careful that \\(\\varnothing\\) must be an element of \\(\\mathcal B\\) in order for \\(\\mathcal B\\) to be a sigma algebra. \\(\\varnothing\\) is certainly a subset of any set, but \\(\\varnothing\\) needs to be an element of \\(\\mathcal B\\) as a collection of sets.\n\nThe smallest sigma algebra, called the trivial sigma algebra, is \\(\\{ \\varnothing, S \\}\\) for a sample space \\(S\\). When \\(S\\) is uncountable, we usually don’t use the power set as a sigma algebra. Instead, we typically opt for using the Borel sigma algebra.\nFor a topological space \\(S\\), the Borel sigma algebra, denoted \\(\\mathcal B(S)\\) is the smallest sigma algebra containing all open sets.\nDefinition. Let \\(X\\) be a set and \\(\\tau\\) be a family of subsets of \\(X\\). Then \\(\\tau\\) is a topology and \\((X, \\tau)\\) is a topological space if\n\nBoth the empty set and \\(X\\) are elements in \\(\\tau\\).\nAny union of elements of \\(\\tau\\) is an element of \\(\\tau\\).\nAny intersection of finitely many elements of \\(\\tau\\) is an element of \\(\\tau\\).\n\nThe members of \\(\\tau\\) are called open sets in \\(X\\).\nWhen \\(A \\in \\mathcal B\\), we say that \\(A\\) is a measurable set.\n\n\nProbability Measures\nDefinition. If \\((S, \\mathcal B)\\) is a measurable space, then \\(P: \\mathcal B \\to \\mathbb R\\) is a probability measure if:\n\n\\(P(A) \\geq 0\\) for all \\(A \\in \\mathcal B\\). (non-negativity)\n\\(P(S) = 1\\) (unitarity)\nif \\(A_1, A_2, ... \\in \\mathcal B\\) are pairwise disjoint, then \\[P\\left(\\bigcup_{i=1}^\\infty A_i \\right) =\n  \\sum_{i=1}^\\infty P(A_i).\\] (countable additivity)\n\nThese properties are called the axioms of probability, or sometimes Kolmogorov’s axioms.\nIf \\(A \\in \\mathcal B\\) we call \\(A\\) a measurable set.\nIn this course, we may assume that the sets we are working with are measurable. Almost exclusively we will be working with the Borel sigma algebra. While non-measurable sets do exist in this setting, they do not often arise in practice.\n\nTJ asks: “I know it’s possible to demonstrate non-measureable sets non-constructively, but is it possible to demonstrate them constructively?”\nMiller: “I think you have to use infinite series/sets [and the axiom of choice].”"
  },
  {
    "objectID": "week1/week1.html#probability-measure-on-a-countable-set",
    "href": "week1/week1.html#probability-measure-on-a-countable-set",
    "title": "Week 1",
    "section": "Probability measure on a countable set",
    "text": "Probability measure on a countable set\nSuppose that \\(S = \\{ s_1, s_2, ... \\}\\) is a countable set.\nLet \\(p_1, p_2, ... \\geq 0\\) such that \\(\\sum_{i=1}^\\infty p_i = 1\\).\nFor \\(A \\subset S\\), define \\[P(A) = \\sum_{i=1}^\\infty p_i \\mathbb 1(i \\in A).\\]\nWe will write that \\(\\mathbb 1(\\cdot)\\) to denote the indicator function, where\n\\[\\mathbb 1(C) = \\left\\{ \\begin{array}{ll}\n1 & \\text{ if condition } C \\text{ is true} \\\\\n0 & \\text{ if condition } C \\text{ is false}\n\\end{array}\n\\right.\\]\nSuppose you toss a fair coin until you get heads. Then \\(p_k\\), the probability that you toss the coin \\(k\\) times, is \\((1/2)^k\\). This defines a probability measure on \\(S = \\{ 1, 2, ... \\}\\).\nWe could imagine measuring how long a lightbulb lasts until it dies after being left on. It could die at any non-negative time \\(t \\geq 0\\). The probability \\(P([0,t))\\) be the probability the lightbulb dies before time \\(t\\). This defines a probability measure on \\(S = [0,\\infty).\\) (Of course, \\([0,\\infty)\\) is a continuous example and not a countable set).\nFor any probability measure, we have that:\n\n\\(P(A^c) = 1 - P(A)\\)\n\\(P(\\varnothing) = 0\\)\n\\(P(A) \\leq 1\\)\nif \\(A \\subset B\\) then \\(P(A) \\leq P(B)\\)\n\\(P(A) = P(A \\cap B) + P(A \\cap B^c)\\)\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\).\n\nProofs:\n\n\\(P(S) = 1\\), and \\(A, A^c\\) are pairwise disjoint and a partition of \\(S\\), so \\(1 = P(S) = P(A^c \\cup A) = P(A) + P(A^c)\\). Subtracting from both sides, \\(P(A) = 1 - P(A^c)\\).\n\\(\\varnothing\\) and \\(S\\) are disjoint, so \\(1 = P(S) = P(S) + P(\\varnothing)\\). Subtracting from both sides, we have that \\(1 - 1 = P(\\varnothing)\\)\nWe have from 1 that \\(1 - P(A^c) = P(A)\\), and \\(P(A^c) \\geq 0\\), so then \\(P(A) \\leq 1\\)\nWe can write that \\(B \\backslash A\\) and \\(A\\) as disjoint sets since \\(A \\subset B\\). Then \\(P(B) = P(A \\cup B \\backslash A) = P(A) + P(B \\backslash A)\\). Since \\(P(B \\backslash A)\\) we have that \\(P(B) \\geq P(A)\\).\nWe need to show that \\(A = (A \\cap B) \\cup (A \\cup B^c)\\). If \\(a \\in A\\) then either \\(a \\in B\\) or \\(a \\in B^c\\), but not both by the definition of complement. Therefore \\(A \\cap B\\) and \\(A \\cap B^c\\) are disjoint and their union is equal to \\(A\\). Hence \\(P(A) = P(A \\cap B \\bigcup A \\cap B^c) = P(A \\cap B) + P(A \\cap B^c)\\).\nFirst, note that \\(A \\cup B = A \\cap (B \\backslash A)\\). Thus \\(P(A \\cup B) = P(A \\cup (B \\backslash A))\\). Since the latter are disjoint, we establish that \\(P(A \\cup B) = P(A) + P(B \\backslash A)\\). Now if we consider that \\(B = (B \\backslash A) \\cup (A \\cap B)\\), and that these are disjoint sets, we have that \\(P(B) = P(B \\backslash A) + P(A \\cap B)\\). Rearranging, we have that \\(P(B \\backslash A) = P(B) - P(A \\cap B)\\). Substituting, now we have that \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) as desired."
  },
  {
    "objectID": "week1/week1.html#properties-of-probability-measures",
    "href": "week1/week1.html#properties-of-probability-measures",
    "title": "Week 1",
    "section": "Properties of Probability Measures",
    "text": "Properties of Probability Measures\nLaw of total probability: for any partition \\(B_1, B_2, ...\\) of \\(S\\), we have that \\[P(A) = \\sum P(A \\cap B_i)\\]\nBoole’s inequality (aka union bound): For \\(A_1, A_2, ...\\),\n\\[P(\\bigcup_{i=1}^\\infty A_i) \\leq \\sum_{i=1}^\\infty P(A_i).\\]\nBonferroni’s inequality: For any \\(A_1, A_2,...\\),\n\\[P\\left(\\bigcap_{i=1}^\\infty A_i \\right) \\geq 1 - \\sum_{i=1}^\\infty P(A_i^c).\\]\nBoole’s inequality is often useful when we want to show that some event has probability near zero. For example, \\(P(E) = P(A_1 \\cup A_2 \\cup A_3) \\leq P(A_1) + P(A_2) + P(A_3) \\leq 3\\epsilon\\)."
  },
  {
    "objectID": "week1/week1.html#selecting-k-items-from-n-options",
    "href": "week1/week1.html#selecting-k-items-from-n-options",
    "title": "Week 1",
    "section": "Selecting \\(k\\) items from \\(n\\) options",
    "text": "Selecting \\(k\\) items from \\(n\\) options\n\n\n\n\nwithout replacement\nwith replacement\n\n\n\n\nordered\n\\(\\frac{n!}{(n-k)!}\\)\n\\(n^k\\)\n\n\nunordered\n\\({n \\choose k}\\)\n\\({ n + k - 1 \\choose k }\\)"
  },
  {
    "objectID": "week1/week1.html#determining-the-leading-factor-in-stirlings-formula",
    "href": "week1/week1.html#determining-the-leading-factor-in-stirlings-formula",
    "title": "Week 1",
    "section": "Determining the Leading Factor in Stirling’s Formula",
    "text": "Determining the Leading Factor in Stirling’s Formula\nStirling’s formula is that for large values of \\(n\\), the following is a good approximation for the factorial function:\n\\[ n! \\approx \\frac{n^n}{e^n} \\sqrt{2 \\pi n}. \\]\nI’ll concern myself with, as an exercise, showing the leading factor \\(n^n e^{-n}\\) is correct.\nFirst, observe the relationship between \\(n!\\) and \\(n^n\\):\n\\[n! = \\underbrace{n \\cdot (n-1) \\cdots 1}_{n \\text{ terms}} < \\underbrace{n \\cdot n \\cdots n}_{n \\text{ times}} = n^n\\]\nThis establishes that"
  },
  {
    "objectID": "week2/week2.html",
    "href": "week2/week2.html",
    "title": "Week 2",
    "section": "",
    "text": "Conditional Probability and Independence\nIf we go back to the formula for sampling with replacement, the \\(-1\\) term comes from the fact that when converting from the number of bins we could put balls into to the number of dividers between the bins, there’s one less divider than there are bins.\nThat formula was \\[ {n + k - 1 \\choose k} \\] so we could think about how to put \\(k\\) balls into \\(n\\) bins, or instead \\(k\\) balls into \\(n-1\\) dividers, or we could think about there being \\(n-1\\) blue balls and \\(k\\) red balls and the blue balls represent the dividers, so now we’re describing choosing \\(k\\) balls to be red out of \\(n + k - 1\\) balls.\nWe have only been so far considering events and outcomes in the sample space \\(S\\). Often it’s most useful to work with functions of the outcome.\nFor instance, suppose a coin is tossed \\(N\\) times.\nA natural definition of the sample space would be \\(S = \\{ 0, 1 \\}^N\\), that is all sequences of \\(N\\) zeroes or ones.\nDefine \\(X\\) to be the number of times that heads comes up.\nIf we only want to evaluate whether the coin is biased, we may as well work with \\(X\\) rather than the whole sequence.\n\\(X\\) can be thought of as a function from the sample space \\(S\\) to the set of integers.\nDefinition. A random variable \\(X\\) is a function from the sample space equipped with sigma algebra \\(\\Omega\\) to the real numbers \\(X: S \\to \\mathbb R\\). Technically it must be a measurable function, that is \\(X^{-1}(A)\\) must be a measurable set for all measurable sets \\(A \\in \\mathcal B(\\mathbb R)\\). But we won’t worry about this so much in this course.\nIn other words, when the outcome is \\(s \\in S\\), the random variable takes the value \\(X(s)\\) which is some real number.\nThe probability that \\(X\\) takes value \\(x\\), denoted \\(P(X=x)\\), is \\[P(X=x) = P(\\{s \\in S \\colon X(s) = x \\})\\]\nIn the coin tossing example, if \\(s = (s_1, ..., s_N) \\in S = \\{0,1\\}^N\\), then the number of heads \\(X(s) = \\sum_{i=1}^N s_i\\).\nIf the probability of heads is \\(q \\in (0,1)\\), then\n\\[P(\\{s\\}) = \\prod_{i=1}^N q^{s_i}(1-q)^{1-s_i} = q^x (1-q)^{N-x}\\]\nwhere \\(x = \\sum_{i=1}^N s_i\\). Let \\(X(s) = \\sum_{i=1}^N s_i\\).\nThe probability of getting heads \\(x\\) times in \\(N\\) coin tosses is\n\\[P(X=x) = P(\\{ s \\in S \\colon X(s) = x \\}) = \\sum_{s \\in S} P(\\{ s\\})\n\\mathbb 1(X(s) = x)\\] \\[ = \\sum_{s \\in S} q^x (1-q)^{N-x} \\mathbb 1 (X(s)=x)\\] \\[ {N \\choose x} q^x (1-q)^{N-x}\\]\n\\(X\\) is said to follow the binomial distribution with parameters \\(N\\) and \\(q\\). This is denoted by writing \\(X \\sim \\text{Binomial}(N,q)\\).\nWe often think of \\(X\\) as a random quantity, but formally it is a function."
  },
  {
    "objectID": "week2/week2.html#jackpot-scenario",
    "href": "week2/week2.html#jackpot-scenario",
    "title": "Week 2",
    "section": "Jackpot Scenario",
    "text": "Jackpot Scenario\nWhen the pot reached $5M, a “rolldown” occurred in which the prizes for matching 3, 4, or 5 numbers were 10x higher.\n\n\n\nMatch Number\n6\n5\n4\n\n\n\n\nProbability\n1/13,983,815\n1/54,201\n1/1032\n\n\nAll prizes (in 2 years)\n15\n2158\n117685\n\n\nPrize (normal)\nJackpot\n$2,500\n$100\n\n\nPrize in Fall\nJackpot not hit\n$25,000\n$1,000\n\n\n\nIf there were a rolldown in the WINfall lottery, we’d have an expected return on a single ticket as:\n\n(1/54201)*25000 + (1/1032)*1000 + (1/57)*(50)\n\n[1] 2.307431"
  },
  {
    "objectID": "week2/week2.html#hypergeometric-distribution",
    "href": "week2/week2.html#hypergeometric-distribution",
    "title": "Week 2",
    "section": "Hypergeometric Distribution",
    "text": "Hypergeometric Distribution\nThe Hypergeometric\\((N,K,n)\\) distribution gives the probability of matching \\(k\\) numbers from a set of \\(K\\) winning numbers when selecting \\(n\\) from a set of \\(N\\) total.\nWe often say distribution instead of probability measure.\nIn the Winfall lottery, \\(N = 49\\), \\(K=6\\), and \\(n=6\\), and the outcome is the number of matches \\(k\\).\nLetting \\(P\\) denote the Hypergeometric\\((N,K,n)\\) distribution, \\[P(\\{k\\}) = \\frac{{K \\choose k}{N - K \\choose n - k}}{N \\choose n}.\\]\nPlugging \\(k=3, k=4, k=5, k=6\\) into this formula yields the probabilities in the above table."
  },
  {
    "objectID": "week2/week2.html#playing-cards",
    "href": "week2/week2.html#playing-cards",
    "title": "Week 2",
    "section": "Playing Cards",
    "text": "Playing Cards\nWhat’s the probability of drawing 4 cards from a deck and getting 4 aces?\nThe number of possible hands of 4 cards is \\({52 \\choose 4}\\).\nThus the probability of getting all 4 aces is\n\\[\\frac{1}{52 \\choose 4} = \\frac{4!48!}{52!}.\\]\nOr we could think about it sequentially: The probability of drawing an ace on the first card is \\(4/52\\), the next is \\(3/51\\), then \\(2/50\\), and \\(1/49\\) each conditioned on assuming we previously drew an ace card.\n\n\\[ \\frac{4}{52} \\times \\frac{3}{51} \\times \\frac{2}{50} \\times \\frac{1}{49} = \\frac{4!48!}{52!} = \\frac{4! \\cancel{48 \\cdot 47 \\cdots 1}}{52 \\cdot 51 \\cdot 50 \\cdot 49 \\cdot \\cancel{48 \\cdot 47 \\cdots 1}} \\]\nDefinition. The conditional probability of \\(A\\) given \\(B\\) denoted \\(P(A|B)\\) is\n\\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nWe could think of \\(B\\) as the event where 1 ace has already been drawn (and thus represents the scenario where \\(B\\) consists of all the cards except 1 ace). Then,\n\\[P(A | B) =\n\\frac{P(\\{ \\text{Ace} \\clubsuit, \\text{Ace} \\diamondsuit, \\text{Ace} \\spadesuit, \\text{Ace} \\heartsuit\\} \\cap B\\})}{P(B)} = \\frac{3}{51} \\]"
  },
  {
    "objectID": "week2/week2.html#bayes-rule",
    "href": "week2/week2.html#bayes-rule",
    "title": "Week 2",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}.\\]\nMultiplying by \\(P(B)\\) yields:\n\\[P(A \\cap B) = P(A|B) P(B).\\]\nBy symmetry, \\[P(A \\cap B) = P(B|A) P(A).\\]\nIf \\(P(A) > 0\\) and \\(P(B) > 0\\), then \\[P(A|B) = \\frac{P(B|A) P(A)}{P(B)}.\\]\nIf \\(A_1, A_2, ...\\) form a partition of the sample space then\n\\[P(A_i |B) = \\frac{P(B|A_i) P(A_i)}{\\sum_{j=1}^\\infty P(B|A_j) P(A_j)}.\\]"
  },
  {
    "objectID": "week2/week2.html#the-monty-hall-problem",
    "href": "week2/week2.html#the-monty-hall-problem",
    "title": "Week 2",
    "section": "The Monty Hall Problem",
    "text": "The Monty Hall Problem\nOn a game show, there are 3 doors. Behind one door is a car, and behind the other two doors are goats. You win whatever is behind the door you select. First you pick door #1. The game show host then reveals that there is a goat behind door #3. The host then asks “Do you want to stay with #1 or switch to #2?” What would you do and why?\nIt turns out you should always switch. Let \\(D_1, D_2, D_3\\) denote the events that the car is behind door 1, 2, or 3. Let \\(M_1, M_2, M_3\\) denote the event that Monty opens door 1, 2, or 3, respectively.\nWe will assume that there’s equal probability of the car being behind 1, 2, or 3. Additionally, we will assume that he always opens a door that is not the one you picked and which does not have the car behind it.\nBy assumption \\[P(D_1) = P(D_2) = P(D_3) = 1/3.\\]\n\\[P(M_j|D_1) = (1/2) \\mathbb 1 (j \\in \\{2,3\\})\\] \\[P(M_j|D_2) = \\mathbb 1 (j = 3)\\] \\[P(M_j|D_3) = \\mathbb 1 (j = 2)\\]\nHere’s a table of the probability of each possible combination \\(i,j\\) of door that the car is behind \\((i)\\) and the door opened by Monty \\((j)\\):\n\n\n\n\nOpen #1\nOpen #2\nOpen #3\n\n\n\n\nCar in #1\n0\n1/6\n1/6\n\n\nCar in #2\n0\n0\n1/3\n\n\nCar in #3\n0\n1/3\n0\n\n\n\nBy the law of total probability, the probability that Monty opens door #3 is\n\\[P(M_3) = \\sum_{i=1}^3 P(M_3|D_i) P(D_i) = \\frac{1}{2} \\times \\frac{1}{3} +\n1 \\times \\frac{1}{3} + 0 \\times \\frac{1}{3} = \\frac{1}{2}.\\]\nSo by Bayes’ rule the conditional probability of the car being behind door #1, given Monty opened door #3, is\n\\[P(D_1|M_3) = \\frac{P(M_3|D_1) P(D_1)}{P(M_3)} = \\frac{(1/2) \\times (1/3)}{1/2} = \\frac{1}{3}\\]\nMeanwhile, the conditional probability of the car being behind door #2 given that Monty opened door #3 is\n\\[P(D_2 | M_3) = \\frac{P(M_3|D_2) P(D_2)}{P(M_2)} = \\frac{1 \\times (1/3)}{(1/2)} = \\frac{2}{3}\\]\n\nWhat’s wrong with the following reasoning?\nWe can think of the sample space as \\(\\{1,2,3\\}\\) and the outcome as the number that the door is behind, so \\(D_i = \\{i\\}.\\)\nBy conditioning on Monty opening door #3, we are conditioning on the event that the car is behind #1 or #2, that is \\(M_3 = D_3^c = \\{1,2\\}\\). Therefore\n\\[ P(D_1 | M_3) = \\frac{P(D_1 \\cap M_3)}{P(M_3)} \\] \\[ = \\frac{P(\\{1\\} \\cap \\{1,2\\})}{P(\\{1,2\\})} \\] \\[ = \\frac{1/3}{2/3} = \\frac{1}{2}.\\]\nFurther, \\(P(D_2|M_3) = 1 - P(D_1 | M_3) = 1/2\\) so we gain nothing by switching to door #2.\nThe problem is that this doesn’t condition on the fact that Monty will never choose the door with the car. In other words, the door Monty picks depends on your choice: when your door contains a goat, Monty only has one choice: the remaining door with a goat.\nIn essence, we need to define the joint-distribution of \\(D_i\\) and \\(M_j\\).\n\nThe intuition is that the probability gets squished into the other doors, so you get probabilities of \\(1/3\\) and \\(2/3\\)."
  },
  {
    "objectID": "week2/week2.html#independence",
    "href": "week2/week2.html#independence",
    "title": "Week 2",
    "section": "Independence",
    "text": "Independence\nIf we had a coin and we flipped it multiple times, where \\(A\\) represents the event where it comes up heads the first time and \\(B\\) is the event where it comes up heads the second time.\nWe would assume that \\(P(B|A) = P(B)\\).\nBy Bayes’ theorem, \\(P(B|A) = P(A \\cap B)/P(A)\\), that implies that \\(P(A \\cap B) = P(A)P(B)\\). When this holds, we say that \\(A\\) and \\(B\\) are independent.\nOne difference is that the second statement doesn’t require that \\(P(A)\\) is nonzero, but the definition using \\(P(B|A)\\) does.\nIf \\(A\\) and \\(B\\) are independent, then so are \\(A\\) and \\(B^c\\), \\(A^c\\) and \\(B\\), and \\(A^c\\) and \\(B^c\\).\nEvents \\(A_1, ..., A_n\\) are mutually independent if \\[P(\\cap_{i \\in I} A_i) = \\prod_{i \\in I} P(A_i)\\] for every subset \\(I \\subset \\{ 1, ..., n \\}.\\)\nYou might think that \\(P(A_1 \\cap \\cdots \\cap A_n) = P(A_1) \\cdots P(A_n)\\) would be a simpler definition of independence of multiple events, but this is not correct. See Casella & Berger (1.3.10)."
  }
]