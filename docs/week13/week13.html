<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Probability (BST 230) Notes - 13&nbsp; Week 13</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../week14/week14.html" rel="next">
<link href="../week11/week11.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-title">Week 13</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Probability (BST 230) Notes</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Methods (BST 232) Notes</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week1/week1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 1</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week2/week2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 2</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week3/week3.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 3</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week4/week4.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 4</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week5/week5.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 5</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week6/week6.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 6</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week7/week7.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 7</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week8/week8.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 8</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week9/week9.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 9</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week10/week10.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 10</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week11/week11.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 11</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week13/week13.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Week 13</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week14/week14.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 14</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week15/week15.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 15</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#asymptotics-and-convergence" id="toc-asymptotics-and-convergence" class="nav-link active" data-scroll-target="#asymptotics-and-convergence">Asymptotics and Convergence</a>
  <ul class="collapse">
  <li><a href="#deterministic-convergence-and-limit-notation" id="toc-deterministic-convergence-and-limit-notation" class="nav-link" data-scroll-target="#deterministic-convergence-and-limit-notation">Deterministic Convergence and Limit Notation</a></li>
  <li><a href="#weak-law-of-large-numbers" id="toc-weak-law-of-large-numbers" class="nav-link" data-scroll-target="#weak-law-of-large-numbers">Weak Law of Large Numbers</a></li>
  <li><a href="#convergence-in-probability" id="toc-convergence-in-probability" class="nav-link" data-scroll-target="#convergence-in-probability">Convergence in Probability</a></li>
  <li><a href="#almost-sure-convergence" id="toc-almost-sure-convergence" class="nav-link" data-scroll-target="#almost-sure-convergence">Almost Sure Convergence</a></li>
  <li><a href="#strong-law-of-large-numbers" id="toc-strong-law-of-large-numbers" class="nav-link" data-scroll-target="#strong-law-of-large-numbers">Strong Law of Large Numbers</a></li>
  <li><a href="#equivalent-definition-for-almost-sure-convergence" id="toc-equivalent-definition-for-almost-sure-convergence" class="nav-link" data-scroll-target="#equivalent-definition-for-almost-sure-convergence">Equivalent Definition for Almost Sure Convergence</a></li>
  <li><a href="#relationship-between-a.s.-convergence-and-in-probability" id="toc-relationship-between-a.s.-convergence-and-in-probability" class="nav-link" data-scroll-target="#relationship-between-a.s.-convergence-and-in-probability">Relationship between a.s. convergence and in probability</a></li>
  <li><a href="#convergence-in-distribution-background" id="toc-convergence-in-distribution-background" class="nav-link" data-scroll-target="#convergence-in-distribution-background">Convergence in Distribution: Background</a></li>
  <li><a href="#central-limit-theorem" id="toc-central-limit-theorem" class="nav-link" data-scroll-target="#central-limit-theorem">Central Limit Theorem</a>
  <ul class="collapse">
  <li><a href="#example-minimum-of-uniforms" id="toc-example-minimum-of-uniforms" class="nav-link" data-scroll-target="#example-minimum-of-uniforms">Example: Minimum of Uniforms</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#convergence-in-lp" id="toc-convergence-in-lp" class="nav-link" data-scroll-target="#convergence-in-lp">Convergence in <span class="math inline">\(L^p\)</span></a></li>
  <li><a href="#relationships-between-modes-of-convergence" id="toc-relationships-between-modes-of-convergence" class="nav-link" data-scroll-target="#relationships-between-modes-of-convergence">Relationships Between Modes of Convergence</a></li>
  <li><a href="#continuous-mapping-theorem" id="toc-continuous-mapping-theorem" class="nav-link" data-scroll-target="#continuous-mapping-theorem">Continuous Mapping Theorem</a></li>
  <li><a href="#slutskys-theorem" id="toc-slutskys-theorem" class="nav-link" data-scroll-target="#slutskys-theorem">Slutsky’s Theorem</a>
  <ul class="collapse">
  <li><a href="#example-asymptotics-of-t-statistics-for-non-normal-data" id="toc-example-asymptotics-of-t-statistics-for-non-normal-data" class="nav-link" data-scroll-target="#example-asymptotics-of-t-statistics-for-non-normal-data">Example: Asymptotics of <span class="math inline">\(t\)</span> statistics for non-normal data</a></li>
  </ul></li>
  <li><a href="#delta-method" id="toc-delta-method" class="nav-link" data-scroll-target="#delta-method">Delta Method</a>
  <ul class="collapse">
  <li><a href="#example-with-odds-of-an-outcome" id="toc-example-with-odds-of-an-outcome" class="nav-link" data-scroll-target="#example-with-odds-of-an-outcome">Example with Odds of an Outcome</a></li>
  <li><a href="#delta-method-1" id="toc-delta-method-1" class="nav-link" data-scroll-target="#delta-method-1">Delta method</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-title">Week 13</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="asymptotics-and-convergence" class="level1">
<h1>Asymptotics and Convergence</h1>
<p>Outline:</p>
<ul>
<li>Convergence in probability
<ul>
<li>Weak law of large numbers</li>
</ul></li>
<li>Convergence almost surely
<ul>
<li>Strong law of large numbers</li>
</ul></li>
<li>Convergence in distribution
<ul>
<li>Central limit theorem</li>
</ul></li>
<li>Convergence in <span class="math inline">\(L^p\)</span></li>
</ul>
<p>Asymptotics are an essential part of probability &amp; statistics — but why do we care? After all, we never have infinite data.</p>
<p>First, asymptotically, things usually simplify a lot.</p>
<p>Two important ways in which we use asymptotics are:</p>
<ol type="1">
<li>To approximate the finite sample behavior of a procedure. * Often, asymptotics provide a simple but very good approximation to something very complicated. * These approximations are the foundation upon which much of statistics is built.</li>
<li>To provide guarantees of correctness. * If something doesn’t work when you have tons of data, then hoping it will somehow work well on a small amount of data is wishful thinking. Asymptotics provide a sanity check that you are doing something reasonable.</li>
</ol>
<p>In probability, we consider the asymptotics of random variables, which involves stochastic convergence.</p>
<div class="bluetip">
<p>Suppose you are studying the effect of a treatment to reduce tremors in Parkinson’s disease.</p>
<p>You have data on treated subjects, <span class="math inline">\(x_1, ..., x_n\)</span> and controls <span class="math inline">\(y_1, ..., y_n\)</span>.</p>
<p>What is the effect of the treatment? You compute the difference of sample means. Justification?</p>
<ul>
<li>We’re invoking the law of large numbers here.</li>
</ul>
<p>Is there evidence of a treatment effect? You do a t-test. Justification?</p>
<ul>
<li>Based on the asymptotics of normal approximations to the data (to the sample means, which are approximately normal according to the central limit theorem).</li>
</ul>
<p>You want to do a larger study. How many subjects should you use? You do power calculations. Justification?</p>
<ul>
<li>…</li>
</ul>
</div>
<section id="deterministic-convergence-and-limit-notation" class="level2">
<h2 class="anchored" data-anchor-id="deterministic-convergence-and-limit-notation">Deterministic Convergence and Limit Notation</h2>
<p>Let’s briefly review deterministic convergence.</p>
<p>Suppose <span class="math inline">\(x_1, ..., x_n\)</span> is a sequence of real numbers.</p>
<p>We say that <span class="math inline">\(x_n\)</span> converges to <span class="math inline">\(x\)</span> if for all <span class="math inline">\(\varepsilon &gt; 0\)</span>, there exists <span class="math inline">\(N\)</span> such that for all <span class="math inline">\(n \geq N\)</span>, <span class="math inline">\(|x_n - x| &lt; \varepsilon\)</span>.</p>
<p>In other words, for <span class="math inline">\(n\)</span> sufficiently large, <span class="math inline">\(|x_n - x|&lt;\varepsilon\)</span>.</p>
<p>The following are equivalent ways of denoting that <span class="math inline">\(x_n\)</span> converges to x:</p>
<p><span class="math display">\[x_n \to \infty \; \; \text{ as } n \to \infty\]</span></p>
<p><span class="math display">\[x_n \xrightarrow[n \to \infty]{} x\]</span></p>
<p><span class="math display">\[\lim_{n \to \infty} x_n = x.\]</span></p>
<p>Note that <span class="math inline">\(x_n \to x\)</span> if and only if <span class="math inline">\(\lim_{n\to\infty} |x_n - x| = 0\)</span>.</p>
</section>
<section id="weak-law-of-large-numbers" class="level2">
<h2 class="anchored" data-anchor-id="weak-law-of-large-numbers">Weak Law of Large Numbers</h2>
<p>Roughly speaking, the law of large numbers (LLN) says that the sample mean converges to the mean.</p>
<p>There are many different versions of LLN that apply under different conditions.</p>
<p>Weak LLN: If <span class="math inline">\(Y_1, ..., Y_n\)</span> are i.i.d. random variables such that <span class="math inline">\(\mathbb{E}Y_1 = \mu\)</span> and <span class="math inline">\(\text{Var}(Y_1) &lt; \infty\)</span>, then for all <span class="math inline">\(\varepsilon &gt; 0\)</span>,</p>
<p><span class="math display">\[P \left( \left\vert \frac{1}{n} \sum_{i=1}^n Y_i - \mu \right\vert &gt; \varepsilon \right) \to 0\]</span></p>
<p>as <span class="math inline">\(n \to \infty\)</span>.</p>
<p>The proof uses Chebyshev’s inequality.</p>
</section>
<section id="convergence-in-probability" class="level2">
<h2 class="anchored" data-anchor-id="convergence-in-probability">Convergence in Probability</h2>
<p>The Weak LLN is an example of convergence in probability.</p>
<p>A sequence of random variables <span class="math inline">\(X_1, X_2, ...\)</span> converges in probability to a random variable <span class="math inline">\(X\)</span> if for all <span class="math inline">\(\varepsilon &gt; 0\)</span>,</p>
<p><span class="math display">\[P(|X_n - X| &gt; \varepsilon) \xrightarrow[n \to \infty ]{} 0,\]</span></p>
<p>or equivalently,</p>
<p><span class="math display">\[P(|X_n - X| \leq \varepsilon) \xrightarrow[n \to \infty ]{} 1.\]</span></p>
<p>We write <span class="math inline">\(X_n \stackrel{p}{\longrightarrow} X\)</span> to denote convergence in probability.</p>
<p>Other equivalent notations you will see sometimes are</p>
<p><span class="math display">\[X_n \to X \text{ in probability}\]</span></p>
<p><span class="math display">\[X \stackrel{pr}{\longrightarrow} X\]</span></p>
<p><span class="math display">\[\mathop{\mathrm{p-lim}}_{n \to \infty} X_n = X.\]</span></p>
<p>Usually, the limit is a constant, but sometimes the limit is itself a random variable.</p>
<div class="cooltip">
<p>For instance, suppose <span class="math inline">\(X \sim \mathcal N(0,1)\)</span> and</p>
<p><span class="math display">\[Y_1, Y_2, ... \mid X = x \sim \mathcal N(x, \sigma^2) \; \; \text{i.i.d.}\]</span></p>
<p>Then <span class="math display">\[\frac{1}{n} \sum_{i=1}^n Y_i \xrightarrow[n \to \infty]{p} X.\]</span></p>
<p>Here, the limit is itself a random variable.</p>
</div>
</section>
<section id="almost-sure-convergence" class="level2">
<h2 class="anchored" data-anchor-id="almost-sure-convergence">Almost Sure Convergence</h2>
<p>Sometimes, a stronger form of convergence can be established.</p>
<p>A sequence of random variables <span class="math inline">\(X_1, X_2, ...\)</span> converges almost surely to a random variable <span class="math inline">\(X\)</span> if</p>
<p><span class="math display">\[P\left( \lim_{n\to \infty} X_n = X\right) = 1.\]</span></p>
<p>More generally, we say an event <span class="math inline">\(E\)</span> occurs almost surely if <span class="math inline">\(P(E) = 1\)</span>.</p>
<p>We write <span class="math inline">\(X_n \stackrel{\text{a.s.}}{\longrightarrow } X\)</span> to denote almost sure convergence.</p>
<p>Some equivalent notations you will see sometimes are:</p>
<p><span class="math display">\[X_n \to X \; \; \text{a.s.}\]</span> <span class="math display">\[\lim_{n \to \infty } X_n \stackrel{a.s.} X\]</span> <span class="math display">\[X_n \to X \text{ with probability }1\]</span></p>
<p>Recall that a random variable is defined as a function mapping from the sample space to <span class="math inline">\(\mathbb{R}\)</span>. So for each <span class="math inline">\(n\)</span>, <span class="math inline">\(X_n : S \to \mathbb{R}\)</span>. <span class="math inline">\(X(s)\)</span> is a fixed value for a given <span class="math inline">\(s\)</span>.</p>
<p>So what we’re really looking at in almost sure convergence is “does <span class="math inline">\(X_n(s) \xrightarrow[n \to \infty]{} X(s)\)</span>?”</p>
<p>We could define some event that is all the elements of the sample space for which this happens: <span class="math display">\[E \coloneqq \{ s \in S : X_n(s) \longrightarrow X(s)\}.\]</span></p>
<p>Sometimes sets like <span class="math inline">\(E\)</span> might fail to be measurable, but in general we won’t worry about that in this class.</p>
<p><span class="math inline">\(P(E) = 1\)</span> if and only if <span class="math inline">\(X_n \xrightarrow[]{a.s.} X\)</span>.</p>
<div class="hottip">
<p>How is almost sure convergence stronger than convergence in probability?</p>
<p>Firstly, almost sure convergence implies convergene in probability, so it is stronger in the logic sense.</p>
<p>Consider the case where <span class="math inline">\(x\)</span> is some fixed number.</p>
<p>For example, if one were taking draws from a binary random variable. If one drew mostly zeroes but occasionally got a 1, if that 1 happens infinitely rarely, then we would have convergence in probability to 0, but we wouldn’t have almost sure convergence because there is no <span class="math inline">\(N\)</span> such that for some <span class="math inline">\(\varepsilon\)</span>, all of the <span class="math inline">\(X_n\)</span> with <span class="math inline">\(n \geq N\)</span> are close to zero.</p>
</div>
<p>This makes it relatively easy to reason about a.s. convergence by reducing to reasoning about deterministic sequences.</p>
<p>Why is it necessary to allow for a set <span class="math inline">\(E^c\)</span> with probability 0?</p>
<ul>
<li>Suppose <span class="math inline">\(X_1, X_2, ... \sim \text{Bernoulli}(q)\)</span> i.i.d. There are sequences <span class="math inline">\(x_1, x_2, ... \in \{ 0, 1 \}\)</span> such that <span class="math inline">\(\frac{1}{n} \sum_{i=1}^n x_i\)</span> doesn’t converge to <span class="math inline">\(q\)</span>, but the set of all such sequences has probability 0.</li>
</ul>
<p>For example, if one considers sequences of repeated 0s and 1s where one concatenates strings of 0s or 1s (alternating) of length <span class="math inline">\(10^i\)</span> for the <span class="math inline">\(i\)</span>th string. Clearly this sequence that starts with 1 zero, 10 1s, 100 0s, 1000 1s, etc., is just oscillating back and forth in its cumulative mean without converging.</p>
</section>
<section id="strong-law-of-large-numbers" class="level2">
<h2 class="anchored" data-anchor-id="strong-law-of-large-numbers">Strong Law of Large Numbers</h2>
<p>The Weak LLN shows that the sample mean converges in probability.</p>
<p>The strong LLN shows that the sample mean converges almost surely.</p>
<p>Strong LLN: If <span class="math inline">\(X_1, X_2, ...\)</span> are i.i.d. and <span class="math inline">\(\mathbb{E}|X| &lt; \infty\)</span>, then <span class="math display">\[\frac{1}{n} \sum_{i=1}^n X_i \xrightarrow[n \to \infty]{a.s.} \mathbb{E}X.\]</span></p>
<p>This is harder to show, so we won’t prove it here. Optional reading: See Durrett, Section 1.7 for the proof.</p>
</section>
<section id="equivalent-definition-for-almost-sure-convergence" class="level2">
<h2 class="anchored" data-anchor-id="equivalent-definition-for-almost-sure-convergence">Equivalent Definition for Almost Sure Convergence</h2>
<p>It turns out that <span class="math inline">\(X_n \stackrel{a.s.}{\longrightarrow} X\)</span> if and only if</p>
<p><span class="math inline">\(P\left( \lim_{n\to\infty} |X_n - X| &lt; \varepsilon \right) = 1.\)</span>$</p>
<p>for all <span class="math inline">\(\varepsilon &gt; 0\)</span>.</p>
<p>Proof: Define the following events: <span class="math display">\[E_{\varepsilon} = \{ s \in S : \limsup_{n \to \infty} |X_n(s) - X(s)| &lt; \varepsilon\},\]</span></p>
<p><span class="math display">\[E = \{ s \in S : \lim_{n\to\infty} |X_n(s) - X(s)| = 0\}.\]</span></p>
<p>We can analyze these events using properties of deterministic convergence. First, if <span class="math inline">\(X_n \stackrel{a.s.}{\longrightarrow} X\)</span> …</p>
</section>
<section id="relationship-between-a.s.-convergence-and-in-probability" class="level2">
<h2 class="anchored" data-anchor-id="relationship-between-a.s.-convergence-and-in-probability">Relationship between a.s. convergence and in probability</h2>
<p>If <span class="math inline">\(X_n \stackrel{a.s.}{\longrightarrow} X\)</span> then <span class="math inline">\(X_n \stackrel{p}{\longrightarrow} X\)</span>.</p>
<p>However, the converse is not true: there are sequences that converge in probability but not almost surely.</p>
<p>A classic example: Suppose <span class="math inline">\(X \sim \text{Uniform}(0,1)\)</span> and</p>
<p><span class="math display">\[
\begin{aligned}
Y_1 = \mathbb{1}(0 &lt; X &lt; 1) \quad &amp; Y_2 = \mathbb{1}(0 &lt; X &lt; \frac{1}{2}) \quad &amp; Y_3 = \mathbb{1}(\frac{1}{2} \leq X &lt; 1) \\
Y_4 = \mathbb{1}(0 &lt; X &lt; \frac{1}{3}) \quad &amp; Y_5 = \mathbb{1}(\frac{1}{3} \leq X &lt; \frac{2}{3}) &amp; Y_6 = \mathbb{1}(\frac{2}{3} \leq X &lt; 1)
\end{aligned}
\]</span></p>
<p>and so forth. Then for any <span class="math inline">\(\varepsilon &gt; 0\)</span>, <span class="math inline">\(P(|Y_n| &gt; \varepsilon) \to 0\)</span>, so</p>
<p><span class="math display">\[Y_n \stackrel{p}{\longrightarrow} 0,\]</span></p>
<p>because we’re getting more and more zeroes as <span class="math inline">\(n\)</span> increases.</p>
<p>However, <span class="math inline">\(Y_n\)</span> does not converge a.s. since <span class="math inline">\(Y_n = 0\)</span> and <span class="math inline">\(Y_n = 1\)</span> both occur infinitely many times. In fact, in the example, <span class="math inline">\(P(Y_n \text{ fails to converge}) = 1\)</span>.</p>
<p>We can make the last statement a little bit more formal by defining the set of events which converge:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Co}&amp;\text{nvergent Events} = \\
&amp; \{s \in S : \exists y \in \mathbb R \text{ such that } \\
&amp; \forall \varepsilon &gt; 0, \;\; \forall \text{ sufficiently large } n, |Y_n(s) - y| &lt; \varepsilon \}
\end{aligned}
\]</span></p>
<p>And then take the complement of this set.</p>
</section>
<section id="convergence-in-distribution-background" class="level2">
<h2 class="anchored" data-anchor-id="convergence-in-distribution-background">Convergence in Distribution: Background</h2>
<p>Convergence in probability is often easier to show than a.s. convergence.</p>
<p>There is an even weaker form of convergence that holds even more generally, called convergence in distribution.</p>
<p>A sequence of random variables <span class="math inline">\(X_1, X_2,...\)</span> convergence in distribution to a random variable <span class="math inline">\(X\)</span> if</p>
<p><span class="math display">\[F_{X_n}(x) \xrightarrow[n \to \infty]{} F_X(x)\]</span></p>
<p>at all points <span class="math inline">\(x \in \mathbb{R}\)</span> where <span class="math inline">\(F_X\)</span> is continuous. Here <span class="math inline">\(F_{X_n}\)</span> and <span class="math inline">\(F_X\)</span> denote the cdfs of <span class="math inline">\(X_n\)</span> and <span class="math inline">\(X\)</span> respectively.</p>
<p>We write <span class="math inline">\(X_n \stackrel{d}{\longrightarrow} X\)</span> to denote convergence in distribution.</p>
<p><img src="standalone_figures/converging_logistics/converging_logistics.svg" class="img-fluid"></p>
<p>Convergence in distribution is also called “weak convergence.”</p>
<p>The following are equivalent ways of writing <span class="math inline">\(X_n \stackrel{d}{\longrightarrow} X\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
X_n \stackrel{D}{\longrightarrow} X \quad \quad &amp; X_n \Rightarrow X \\
X_n \stackrel{\mathcal L}{\longrightarrow} X \quad \quad&amp; X_n \rightsquigarrow X \\
\mathcal L(X_n) \longrightarrow \mathcal L(X) \quad \quad &amp; X_n \to X \text{ in distribution.}
\end{aligned}
\]</span></p>
<p>If <span class="math inline">\(D\)</span> is the distribution of <span class="math inline">\(X\)</span>, then <span class="math inline">\(X_n \stackrel{d}{\longrightarrow} D\)</span> means <span class="math inline">\(X_n \stackrel{d} X\)</span>.</p>
</section>
<section id="central-limit-theorem" class="level2">
<h2 class="anchored" data-anchor-id="central-limit-theorem">Central Limit Theorem</h2>
<p>The central limit theorem (CLT) provides an example of convergence in distribution.</p>
<p>Central limit theorem: If <span class="math inline">\(X_1, X_2, ...\)</span> are i.i.d. and <span class="math inline">\(\text{Var}(X_1) &lt; \infty\)</span>, then</p>
<p><span class="math display">\[\frac{1}{\sqrt{n}} \sum_{i=1}^n (X_i - \mu) \xrightarrow[n\to\infty]{d} \mathcal N(0,\sigma^2)\]</span></p>
<p>where <span class="math inline">\(\mu = \mathbb{E}X_1\)</span> and <span class="math inline">\(\sigma^2 = \text{Var}(X_1)\)</span>.</p>
<p>The LLN tells us that <span class="math inline">\(\bar X - \mu \longrightarrow 0\)</span>. In contrast, the CLT says that <span class="math inline">\(\sqrt{n}(\bar X - \mu)\)</span> converges in distribution to <span class="math inline">\(\mathcal N(0, \sigma^2)\)</span>.</p>
<p>Convergence in distribution is really a property of the sequence of distributions, rather than a the sequence of random variables.</p>
<p>In particular, any dependence among <span class="math inline">\(X_1, X_2, ...\)</span> is irrelevant to convergence in distribution. All that matters is their distributions <span class="math inline">\(\mathcal L(X_1), \mathcal L(X_2), ...\)</span>.</p>
<p>Convergence in distribution means <span class="math inline">\(\mathcal L(X_n)\)</span> is close (in a certain sense) to <span class="math inline">\(\mathcal L(X)\)</span> as <span class="math inline">\(n \to \infty\)</span>.</p>
<p>In contrast, a.s. convergence means <span class="math inline">\(X_n(s)\)</span> gets close to <span class="math inline">\(X(s)\)</span> as <span class="math inline">\(n \to \infty\)</span> for all <span class="math inline">\(s\)</span> in some set with probability 1.</p>
<p>And convergence in probability means <span class="math inline">\(X_n\)</span> is close to <span class="math inline">\(X\)</span> with high probability as <span class="math inline">\(n \to \infty\)</span>.</p>
<section id="example-minimum-of-uniforms" class="level3">
<h3 class="anchored" data-anchor-id="example-minimum-of-uniforms">Example: Minimum of Uniforms</h3>
<p>This is an example of convergence in probability and in distribution that doesn’t involve the LLN or CLT.</p>
<p>Suppose <span class="math inline">\(X_1, X_2, ... \sim \text{Uniform}(0,1)\)</span> iid and define</p>
<p><span class="math display">\[M_n = \min \{ X_1, ..., X_n \}.\]</span></p>
<p>Intuitively, <span class="math inline">\(M_n\)</span> should converge to 0. Formally, for <span class="math inline">\(\varepsilon \in (0,1),\)</span>$</p>
<p><span class="math display">\[\begin{aligned}
P(|M_n - 0| &gt; \varepsilon) &amp; = P(M_n &gt; \varepsilon) \\
&amp; = P(X_1 &gt; \varepsilon, ..., X_n &gt; \varepsilon) \\
&amp; = \prod_{i=1}^n P(X_i &gt; \varepsilon) \\
&amp; = (1-\varepsilon)^n \xrightarrow[n\to\infty]{} 0.
\end{aligned}\]</span></p>
<p>Therefore <span class="math inline">\(M_n \xrightarrow[]{p} 0.\)</span></p>
<p>So <span class="math inline">\(M_n \xrightarrow[]{p} 0\)</span>, but can we say more? How quickly does <span class="math inline">\(M_n\)</span> converge to 0? What is the asymptotic distribution of <span class="math inline">\(M_n\)</span> near 0?</p>
<p>From the calculation above, if we set <span class="math inline">\(\varepsilon = x/n\)</span>, then <span class="math display">\[P(n M_n \leq x ) = 1 - P(M_n &gt; x/n) \xrightarrow[n\to\infty]{} 1 - \exp(-x),\]</span> the cdf of <span class="math inline">\(\text{Exponential}(1)\)</span>. Therefore,</p>
<p><span class="math display">\[nM_n \xrightarrow[n\to\infty]{d} \text{Exponential}(1).\]</span></p>
<p>Thus <span class="math inline">\(M_n\)</span> is approximately distributed as <span class="math inline">\(\text{Exponential}(n)\)</span> when <span class="math inline">\(n\)</span> is large. This gives us a precise characterization of the asymptotic distribution of <span class="math inline">\(M_n\)</span>.</p>
</section>
</section>
</section>
<section id="convergence-in-lp" class="level1">
<h1>Convergence in <span class="math inline">\(L^p\)</span></h1>
<p>Suppose <span class="math inline">\(1 \leq p &lt; \infty\)</span> and <span class="math inline">\(X, X_1, X_2, ... \in L^p\)</span>, that is <span class="math inline">\(\mathbb{E}|X|^p &lt; \infty\)</span> and <span class="math inline">\(\mathbb{E}|X_n|^p &lt; \infty\)</span> for all <span class="math inline">\(n\)</span>.</p>
<p>Then <span class="math inline">\(X_1, X_2, ...\)</span> converges in <span class="math inline">\(L^p\)</span> to <span class="math inline">\(X\)</span> if</p>
<p><span class="math display">\[\mathbb{E}|X_n - X|^p \xrightarrow[n\to\infty]{} 0.\]</span></p>
<p>We write <span class="math inline">\(X_n \xrightarrow[]{L^p} X\)</span> to denote convergence in <span class="math inline">\(L^p\)</span>.</p>
<p>Convergence in <span class="math inline">\(L^p\)</span> is also called convergence in the <span class="math inline">\(p\)</span>th mean.</p>
<p>The most important cases are when <span class="math inline">\(p = 1\)</span> or <span class="math inline">\(p = 2\)</span>.</p>
<ul>
<li><span class="math inline">\(\mathbb{E}|X_n - X| \to 0\)</span> is called convergence in mean</li>
<li><span class="math inline">\(\mathbb{E}|X_n - X|^2\)</span> is called convergence in mean square.</li>
</ul>
<p>If <span class="math inline">\(X_n \xrightarrow[]{L^p} X\)</span> then <span class="math inline">\(\mathbb{E}|X_n|^p \to \mathbb{E}|X|^p\)</span>.</p>
</section>
<section id="relationships-between-modes-of-convergence" class="level1">
<h1>Relationships Between Modes of Convergence</h1>
<p>If <span class="math inline">\(X_n \xrightarrow[]{a.s.} X\)</span> then <span class="math inline">\(X_n \xrightarrow[]{p} X\)</span>.</p>
<p>Partial converse: if <span class="math inline">\(X_n \xrightarrow[]{p} X\)</span> then there is a subsequence <span class="math inline">\(n_1, n_2, ...\)</span> such that <span class="math inline">\(X_{n_k} \xrightarrow[]{a.s.} X\)</span>.</p>
<p>If <span class="math inline">\(X_n \xrightarrow[]{p} X\)</span> then <span class="math inline">\(X \xrightarrow[]{d} X\)</span>.</p>
<p>Partial converse: if <span class="math inline">\(X_n \xrightarrow[]{d}\)</span> and <span class="math inline">\(P(X=c) = 1\)</span> for some constant <span class="math inline">\(c\)</span>, then <span class="math inline">\(X_n \xrightarrow[]{p} X\)</span>.</p>
<p>If <span class="math inline">\(X_n \xrightarrow[]{L^p} X\)</span> then <span class="math inline">\(X_n \xrightarrow[]{p} X\)</span>.</p>
<p>Partial converse: if <span class="math inline">\(X_n \xrightarrow[]{p} X\)</span> and <span class="math inline">\(|X_n| \leq |Y|\)</span> for some <span class="math inline">\(Y \in L^p\)</span>, then <span class="math inline">\(|X| \in L^p\)</span> and <span class="math inline">\(X_n \xrightarrow[]{L^p} X\)</span>.</p>
</section>
<section id="continuous-mapping-theorem" class="level1">
<h1>Continuous Mapping Theorem</h1>
<p>Often we know a sequence of <span class="math inline">\(X_n\)</span> converges, but we really want to know about <span class="math inline">\(g(X_n)\)</span> for some function <span class="math inline">\(g(x)\)</span>.</p>
<p>The <span class="vocab">Continuous Mapping Theorem</span> states that: Suppose <span class="math inline">\(X, X_1, X_2, ... \in \mathcal X\)</span> and <span class="math inline">\(g : \mathcal X \to \mathbb R\)</span> is a function that is continuous at all <span class="math inline">\(x\)</span> in some set <span class="math inline">\(A \subset \mathcal X\)</span> such that <span class="math inline">\(P(X \in A) = 1\)</span>.</p>
<p>If <span class="math inline">\(X_n \xrightarrow[]{a.s.} X\)</span> then <span class="math inline">\(g(X_n) \xrightarrow[]{a.s.} g(X)\)</span>. If <span class="math inline">\(X_n \xrightarrow[]{p} X\)</span> then <span class="math inline">\(g(X_n) \xrightarrow[]{p} g(X)\)</span>. If <span class="math inline">\(X_n \xrightarrow[]{d} X\)</span> then <span class="math inline">\(g(X_n) \xrightarrow[]{d} g(X)\)</span>.</p>
<p>Example: If the sample variance <span class="math inline">\(S_n^2\)</span> converges (a.s., or in probability, or in distribution) to <span class="math inline">\(\sigma^2\)</span> then the sample standard deviation <span class="math inline">\(S_n = \sqrt{S_n^2}\)</span> converges in the same sense to <span class="math inline">\(\sigma\)</span>.</p>
</section>
<section id="slutskys-theorem" class="level1">
<h1>Slutsky’s Theorem</h1>
<p>Slutsky’s theorem is a result about the convergence of sums, products, or ratios.</p>
<p><span class="vocab">Slutsky’s theorem.</span> If <span class="math inline">\(X_1, X_2, \ldots\)</span> and <span class="math inline">\(Y_1, Y_2, \ldots\)</span> are random variables such that <span class="math inline">\(X_n \xrightarrow{d} X\)</span> and <span class="math inline">\(Y_n \xrightarrow{p} c\)</span> for some random variable <span class="math inline">\(X\)</span> and constant <span class="math inline">\(c\)</span>, then</p>
<ul>
<li><span class="math inline">\(X_n + Y_n \xrightarrow{d} X + c\)</span>,</li>
<li><span class="math inline">\(X_n Y_n \xrightarrow{d} Xc\)</span>, and</li>
<li><span class="math inline">\(X_n / Y_n \xrightarrow{d} X/c\)</span> if <span class="math inline">\(c \neq 0\)</span>.</li>
</ul>
<p>Convergence of <span class="math inline">\(Y_n\)</span> to a constant is necessary; the result doesn’t hold in general if <span class="math inline">\(Y_n \xrightarrow{p} Y\)</span> for a random variable <span class="math inline">\(Y\)</span>.</p>
<section id="example-asymptotics-of-t-statistics-for-non-normal-data" class="level2">
<h2 class="anchored" data-anchor-id="example-asymptotics-of-t-statistics-for-non-normal-data">Example: Asymptotics of <span class="math inline">\(t\)</span> statistics for non-normal data</h2>
<p>Suppose <span class="math inline">\(X_1, \ldots, X_n\)</span> i.i.d. with variance <span class="math inline">\(\sigma^2 \in (0, \infty)\)</span>, and let <span class="math display">\[ T_n = \frac{\sqrt{n}(\bar{X}_n - \mu)}{S_n} \]</span> where <span class="math inline">\(\bar{X}_n\)</span> is the sample mean, <span class="math inline">\(\mu = \mathbb{E}X_1\)</span> is the mean, and <span class="math inline">\(S_n\)</span> is the sample standard deviation.</p>
<p>By the CLT, <span class="math inline">\(\sqrt{n}(\bar{X}_n - \mu) \xrightarrow{d} Z\)</span> where <span class="math inline">\(Z \sim \mathcal{N}(0, \sigma^2)\)</span>.</p>
<p>By the Strong LLN, <span class="math display">\[ S_n^2 = \left( \frac{1}{n-1} \sum_{i=1}^n X_i^2 \right) - \frac{n}{n-1}\bar{X}_n^2 \xrightarrow{\text{a.s.}} \mathbb{E}(X_1^2)-(\mathbb{E}X_1)^2 = \sigma^2. \]</span></p>
<p>Thus, <span class="math inline">\(S_n^2 \xrightarrow{p} \sigma^2\)</span>, so by continuous mapping theorem, <span class="math inline">\(S_n \xrightarrow{p} \sigma\)</span>.</p>
<p>Therefore, by Slutsky’s theorem, <span class="math display">\[ T_n = \frac{\sqrt{n}(\bar{X}_n - \mu)}{S_n} \xrightarrow{d} \frac{Z}{\sigma} \sim \mathcal{N}(0, 1). \]</span> as <span class="math inline">\(n \to \infty\)</span>.</p>
</section>
</section>
<section id="delta-method" class="level1">
<h1>Delta Method</h1>
<p>Suppose we know that <span class="math inline">\(\sqrt{n}(\bar{X}_n - \mu) \xrightarrow{d} \mathcal{N}(0, \sigma^2)\)</span>, for instance, by the CLT.</p>
<p>However, what if we are actually interested in <span class="math inline">\(g(\bar{X}_n)\)</span> for some function <span class="math inline">\(g(x)\)</span>?</p>
<p>The delta method tells us how to derive the asymptotic distribution of <span class="math inline">\(g(\bar{X}_n)\)</span>.</p>
<p>More generally, the delta method applies not only to sample means <span class="math inline">\(\bar{X}_n\)</span> but to arbitrary random variables <span class="math inline">\(Y_n\)</span> and a constant <span class="math inline">\(\theta\)</span> such that <span class="math inline">\(\sqrt{n}(Y_n - \theta) \xrightarrow{d} \mathcal{N}(0, \sigma^2)\)</span>.</p>
<section id="example-with-odds-of-an-outcome" class="level2">
<h2 class="anchored" data-anchor-id="example-with-odds-of-an-outcome">Example with Odds of an Outcome</h2>
<p>Suppose <span class="math inline">\(X_1, \ldots, X_n \sim \text{Bernoulli}(\theta)\)</span> i.i.d.</p>
<p>For instance, outcomes representing success/failure of a medical treatment.</p>
<p>The odds of success are <span class="math inline">\(g(\theta) = \theta / (1 - \theta)\)</span>, and we could estimate this via <span class="math inline">\(g(\bar{X}_n) = \bar{X}_n / (1 - \bar{X}_n)\)</span>.</p>
<p>By the SLLN and the continuous mapping theorem, we know <span class="math inline">\(\bar{X}_n \xrightarrow{\text{a.s.}} \mathbb{E}X_1 = \theta\)</span> and <span class="math inline">\(g(\bar{X}_n) \xrightarrow{\text{a.s.}} \theta / (1 - \theta)\)</span>.</p>
<p>But how variable is the estimate <span class="math inline">\(g(\bar{X}_n)\)</span>? For instance, how could we form approximate standard errors for this estimate?</p>
<p>The delta method provides a simple approximation to the distribution of <span class="math inline">\(g(\bar{X}_n)\)</span> that is asymptotically good.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.2     ✔ readr     2.1.4
✔ forcats   1.0.0     ✔ stringr   1.5.0
✔ lubridate 1.9.2     ✔ tibble    3.2.1
✔ purrr     1.0.1     ✔ tidyr     1.3.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fl">0.3</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">200</span> </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">200</span>, <span class="at">size =</span> <span class="dv">10000</span>, <span class="at">prob =</span> .<span class="dv">3</span>)  <span class="sc">/</span> <span class="dv">10000</span>,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> x<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>x)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>df_curve <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">0</span>, .<span class="dv">7</span>, <span class="at">length.out =</span> <span class="dv">1000</span>),</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="at">y =</span> x<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>x))</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_bw</span>())</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>plt1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> x)) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">bins =</span> <span class="dv">50</span>, <span class="at">fill =</span> <span class="st">'cadetblue'</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">"Distribution of "</span>, <span class="fu">bar</span>(X), <span class="st">" for "</span>, theta, <span class="st">" = 0.3"</span>))) <span class="sc">+</span> <span class="fu">xlim</span>(<span class="fu">c</span>(<span class="dv">0</span>,.<span class="dv">7</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_density(bins = 50, fill = "cadetblue"): Ignoring unknown
parameters: `bins`</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>plt2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"The odds function"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> y)) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">bins =</span> <span class="dv">50</span>, <span class="at">fill =</span> <span class="st">'cadetblue'</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">"Distribution of "</span>, <span class="fu">g</span>(<span class="fu">bar</span>(X)), <span class="st">" for "</span>, theta, <span class="st">" = 0.3"</span>))) <span class="sc">+</span> <span class="fu">xlim</span>(<span class="fu">c</span>(<span class="dv">0</span>,.<span class="dv">7</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_density(bins = 50, fill = "cadetblue"): Ignoring unknown
parameters: `bins`</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>plt1 <span class="sc">/</span> plt2 <span class="sc">/</span> plt3 </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="week13_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="delta-method-1" class="level2">
<h2 class="anchored" data-anchor-id="delta-method-1">Delta method</h2>
<p>Suppose <span class="math inline">\(Y_1, Y_2, \ldots\)</span> is a sequence of random variables such that</p>
<p><span class="math display">\[
\sqrt{n}(Y_n - \theta) \xrightarrow{d} \mathcal{N}(0, \sigma^2)
\]</span></p>
<p>for some <span class="math inline">\(\theta \in \mathbb{R}\)</span> and some <span class="math inline">\(\sigma^2 &gt; 0\)</span>. Suppose <span class="math inline">\(g\)</span> is a function such that the derivative <span class="math inline">\(g'(\theta)\)</span> exists and is nonzero at <span class="math inline">\(\theta\)</span>. Then</p>
<p><span class="math display">\[
\sqrt{n}(g(Y_n) - g(\theta)) \xrightarrow{d} \mathcal{N}(0, (g'(\theta))^2 \sigma^2).
\]</span></p>
<p>If <span class="math inline">\(Y \sim \mathcal{N}(\theta, \sigma^2/n)\)</span> and <span class="math inline">\(g(y) = ay + b\)</span>, then by the affine transformation property, <span class="math inline">\(g(Y) \sim \mathcal{N}(a\theta + b, a^2\sigma^2/n)\)</span>, that is,</p>
<p><span class="math display">\[
\sqrt{n}(g(Y) - g(\theta)) \sim \mathcal{N}(0, (g'(\theta))^2 \sigma^2).
\]</span></p>
<p>The intuition for the delta method is that <span class="math inline">\(g\)</span> is approximately linear near <span class="math inline">\(\theta\)</span>, and <span class="math inline">\(Y_n\)</span> is close to <span class="math inline">\(\theta\)</span> when <span class="math inline">\(n\)</span> is large. Thus, <span class="math inline">\(g(Y_n)\)</span> can be approximated as an affine transformation of <span class="math inline">\(Y_n\)</span>.</p>
<p>Suppose <span class="math inline">\(X_1, \ldots, X_n \sim \text{Bernoulli}(\theta)\)</span> i.i.d. where <span class="math inline">\(\theta \in (0, 1)\)</span>, and let <span class="math inline">\(\sigma^2 = \text{Var}(X_1)\)</span>. Note that <span class="math inline">\(\sigma^2 = \theta(1 - \theta)\)</span>. By the CLT, since <span class="math inline">\(\mathbb{E}X_1 = \theta\)</span> and <span class="math inline">\(\sigma^2 \in (0, \infty)\)</span>,</p>
<p><span class="math display">\[
\sqrt{n}(\bar{X}_n - \theta) \xrightarrow{d} \mathcal{N}(0, \sigma^2).
\]</span></p>
<p>Define <span class="math inline">\(g(\theta) = \theta/(1 - \theta)\)</span>. Then for all <span class="math inline">\(\theta \in (0, 1)\)</span>,</p>
<p><span class="math display">\[
g'(\theta) = \frac{(1 - \theta) - \theta(-1)}{(1 - \theta)^2} = \frac{1}{(1 - \theta)^2} \neq 0.
\]</span></p>
<p>Therefore, by the delta method,</p>
<p><span class="math display">\[
\sqrt{n}(g(\bar{X}_n) - g(\theta)) \xrightarrow{d} \mathcal{N}(0, \frac{\theta}{(1 - \theta)^3}).
\]</span></p>
<p>Thus, using somewhat imprecise notation,</p>
<p><span class="math display">\[
g(\bar{X}_n) \approx \mathcal{N}\left(g(\theta), \frac{\theta}{n(1 - \theta)^3}\right).
\]</span></p>
<p>In particular, the standard error of <span class="math inline">\(g(\bar{X}_n)\)</span> is approximately</p>
<p><span class="math display">\[
\text{se}(g(\bar{X}_n)) \approx \sqrt{\frac{\theta}{n(1 - \theta)^3}}.
\]</span></p>
<p>However, in practice, we don’t know <span class="math inline">\(\theta\)</span>, so we would need to plug in an estimate of <span class="math inline">\(\theta\)</span>, for instance,</p>
<p><span class="math display">\[
\text{se}(g(\bar{X}_n)) \approx \sqrt{\frac{\bar{X}_n}{n(1 - \bar{X}_n)^3}}.
\]</span></p>
<p>We can use this to form approximate confidence intervals for <span class="math inline">\(g(\theta)\)</span>, for instance, an approximate 95% interval would be</p>
<p>$$ g({X}_n) (g({X}_n)).</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../week11/week11.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Week 11</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../week14/week14.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-title">Week 14</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>